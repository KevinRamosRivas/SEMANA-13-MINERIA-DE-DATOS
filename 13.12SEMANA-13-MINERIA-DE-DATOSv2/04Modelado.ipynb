{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MINERÍA DE DATOS\n",
    "## LABORATORIO SEMANA 13\n",
    "### DOCENTE:  Dr. Hugo David Calderon Vilca\n",
    "### INTEGRANTES:\n",
    "- Blas Ruiz, Luis Aaron - 19200069\n",
    "- Huarhuachi Ortega, Andrea Mariana - 19200267\n",
    "- Ramos Rivas, Kevin Keyler - 19200096\n",
    "- Rojas Villanueva, Paula Elianne - 19200266\n",
    "- Torres Talaverano, Luz Elena - 19200294"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descripción de la Cuarta Parte"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este notebook haremos el análisis de texto mediante el modelado de temas. El objetivo final del modelado de temas es encontrar varios temas que estén presentes en su corpus. Cada documento del corpus se compondrá de al menos un tema, si no de varios temas.\n",
    "\n",
    "Para usar una técnica de modelado de temas, debemos proporcionar (1) una matriz de término de documento y (2) la cantidad de temas que le gustaría que el algoritmo recogiera."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analizando los topicos de todo el texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abilities</th>\n",
       "      <th>ability</th>\n",
       "      <th>ablaze</th>\n",
       "      <th>able</th>\n",
       "      <th>abominable</th>\n",
       "      <th>abomination</th>\n",
       "      <th>abominations</th>\n",
       "      <th>absolutely</th>\n",
       "      <th>academy</th>\n",
       "      <th>...</th>\n",
       "      <th>youve</th>\n",
       "      <th>yowza</th>\n",
       "      <th>yuck</th>\n",
       "      <th>yup</th>\n",
       "      <th>zealots</th>\n",
       "      <th>zero</th>\n",
       "      <th>zombies</th>\n",
       "      <th>zone</th>\n",
       "      <th>zurich</th>\n",
       "      <th>ça</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>T1C1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1C2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1C3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1C4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1C5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1C6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1C7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1C8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 4423 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      abandoned  abilities  ability  ablaze  able  abominable  abomination  \\\n",
       "T1C1          1          0        0       0     0           0            0   \n",
       "T1C2          0          0        1       0     1           0            0   \n",
       "T1C3          0          1        1       1     2           0            0   \n",
       "T1C4          0          0        1       0     1           1            0   \n",
       "T1C5          1          1        1       0     0           0            0   \n",
       "T1C6          0          0        2       0     1           0            0   \n",
       "T1C7          0          0        0       0     1           0            0   \n",
       "T1C8          0          0        1       0     1           0            1   \n",
       "\n",
       "      abominations  absolutely  academy  ...  youve  yowza  yuck  yup  \\\n",
       "T1C1             0           0        1  ...      4      0     0    0   \n",
       "T1C2             0           0        0  ...      4      0     0    0   \n",
       "T1C3             1           0        2  ...      1      0     2    0   \n",
       "T1C4             0           1        0  ...      3      0     0    0   \n",
       "T1C5             0           0        0  ...      4      0     0    0   \n",
       "T1C6             0           0        0  ...      2      0     0    0   \n",
       "T1C7             0           0        0  ...     12      1     0    0   \n",
       "T1C8             1           0        0  ...      4      0     0    1   \n",
       "\n",
       "      zealots  zero  zombies  zone  zurich  ça  \n",
       "T1C1        1     1        0     0       0   1  \n",
       "T1C2        0     0        0     0       0   0  \n",
       "T1C3        0     0        1     0       0   0  \n",
       "T1C4        0     2        0     2       0   0  \n",
       "T1C5        0     0        0     0       0   0  \n",
       "T1C6        0     0        0     0       0   0  \n",
       "T1C7        0     0        0     0       1   0  \n",
       "T1C8        0     1        0     0       0   0  \n",
       "\n",
       "[8 rows x 4423 columns]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#leermos la matriz de terminos de documentos\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "data = pd.read_pickle('dtm_stop.pkl')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import los módulos necesarios para LDA con gensim\n",
    "from gensim import matutils, models\n",
    "import scipy.sparse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T1C1</th>\n",
       "      <th>T1C2</th>\n",
       "      <th>T1C3</th>\n",
       "      <th>T1C4</th>\n",
       "      <th>T1C5</th>\n",
       "      <th>T1C6</th>\n",
       "      <th>T1C7</th>\n",
       "      <th>T1C8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>abandoned</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abilities</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ability</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ablaze</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>able</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           T1C1  T1C2  T1C3  T1C4  T1C5  T1C6  T1C7  T1C8\n",
       "abandoned     1     0     0     0     1     0     0     0\n",
       "abilities     0     0     1     0     1     0     0     0\n",
       "ability       0     1     1     1     1     2     0     1\n",
       "ablaze        0     0     1     0     0     0     0     0\n",
       "able          0     1     2     1     0     1     1     1"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Una de las entradas requeridas es una matriz de documento de término\n",
    "tdm = data.transpose()\n",
    "tdm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Vamos a poner la matriz del documento de términos en un nuevo formato gensim, desde df --> matriz dispersa --> corpus gensim\n",
    "sparse_counts = scipy.sparse.csr_matrix(tdm)\n",
    "corpus = matutils.Sparse2Corpus(sparse_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Gensim también requiere un diccionario de todos los términos y su ubicación respectiva en la matriz del documento de términos\n",
    "cv = pickle.load(open(\"cv_stop.pkl\", \"rb\"))\n",
    "id2word = dict((v, k) for k, v in cv.vocabulary_.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the corpus (term-document matrix) and id2word (dictionary of location: term), we need to specify two other parameters - the number of topics and the number of passes. Let's start the number of topics at 2, see if the results make sense, and increase the number from there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.008*\"like\" + 0.005*\"want\" + 0.005*\"need\" + 0.004*\"oh\" + 0.004*\"think\" + 0.004*\"did\" + 0.003*\"yeah\" + 0.003*\"ill\" + 0.003*\"hey\" + 0.003*\"help\"'),\n",
       " (1,\n",
       "  '0.007*\"like\" + 0.005*\"did\" + 0.005*\"want\" + 0.004*\"need\" + 0.004*\"oh\" + 0.003*\"rowan\" + 0.003*\"think\" + 0.003*\"way\" + 0.003*\"tell\" + 0.003*\"little\"')]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ahora que tenemos el corpus (matriz término-documento) e id2word (diccionario de ubicación: término),\n",
    "# necesitamos especificar otros dos parámetros también: el número de temas y el número de pases\n",
    "lda = models.LdaModel(corpus=corpus, id2word=id2word, num_topics=2, passes=10)\n",
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.000*\"like\" + 0.000*\"want\" + 0.000*\"oh\" + 0.000*\"need\" + 0.000*\"think\" + 0.000*\"did\" + 0.000*\"way\" + 0.000*\"yeah\" + 0.000*\"ill\" + 0.000*\"tell\"'),\n",
       " (1,\n",
       "  '0.008*\"like\" + 0.005*\"need\" + 0.004*\"ill\" + 0.004*\"want\" + 0.004*\"did\" + 0.004*\"think\" + 0.003*\"oh\" + 0.003*\"yeah\" + 0.003*\"lets\" + 0.003*\"hes\"'),\n",
       " (2,\n",
       "  '0.008*\"like\" + 0.006*\"want\" + 0.006*\"did\" + 0.005*\"oh\" + 0.004*\"need\" + 0.004*\"think\" + 0.003*\"way\" + 0.003*\"father\" + 0.003*\"little\" + 0.003*\"family\"')]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LDA para num_topics = 3\n",
    "lda = models.LdaModel(corpus=corpus, id2word=id2word, num_topics=3, passes=10)\n",
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.010*\"like\" + 0.006*\"want\" + 0.005*\"did\" + 0.005*\"need\" + 0.005*\"oh\" + 0.005*\"think\" + 0.004*\"yeah\" + 0.004*\"hes\" + 0.003*\"ill\" + 0.003*\"rowan\"'),\n",
       " (1,\n",
       "  '0.006*\"like\" + 0.005*\"need\" + 0.004*\"ill\" + 0.004*\"kinbott\" + 0.004*\"youve\" + 0.004*\"laurel\" + 0.003*\"did\" + 0.003*\"oh\" + 0.003*\"think\" + 0.003*\"help\"'),\n",
       " (2,\n",
       "  '0.005*\"like\" + 0.005*\"did\" + 0.004*\"want\" + 0.004*\"way\" + 0.004*\"oh\" + 0.003*\"need\" + 0.003*\"tell\" + 0.003*\"little\" + 0.003*\"people\" + 0.003*\"rowan\"'),\n",
       " (3,\n",
       "  '0.000*\"did\" + 0.000*\"like\" + 0.000*\"want\" + 0.000*\"way\" + 0.000*\"hes\" + 0.000*\"need\" + 0.000*\"father\" + 0.000*\"garrett\" + 0.000*\"family\" + 0.000*\"think\"')]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LDA para num_topics = 4\n",
    "lda = models.LdaModel(corpus=corpus, id2word=id2word, num_topics=4, passes=10)\n",
    "lda.print_topics()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estos temas no se ven muy bien. Hemos intentado modificar nuestros parámetros. Intentemos modificar también nuestra lista de términos."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identificar topicos de solo sustantivos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un truco popular es mirar solo los términos que pertenecen a una parte del discurso (solo sustantivos, solo adjetivos, etc.). Consulte el conjunto de etiquetas de UPenn: https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Vamos a crear una función para extraer sustantivos de una cadena de texto\n",
    "from nltk import word_tokenize, pos_tag\n",
    "\n",
    "def nouns(text):\n",
    "    '''Given a string of text, tokenize the text and pull out only the nouns.'''\n",
    "    is_noun = lambda pos: pos[:2] == 'NN'\n",
    "    tokenized = word_tokenize(text)\n",
    "    all_nouns = [word for (word, pos) in pos_tag(tokenized) if is_noun(pos)] \n",
    "    return ' '.join(all_nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>T1C1</th>\n",
       "      <td>original release date november   wednesday add...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1C2</th>\n",
       "      <td>original release date november   wednesday con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1C3</th>\n",
       "      <td>original release date november   wednesday fin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1C4</th>\n",
       "      <td>original release date november   wednesday and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1C5</th>\n",
       "      <td>original release date november    years ago go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1C6</th>\n",
       "      <td>original release date november   wednesday att...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1C7</th>\n",
       "      <td>original release date november   at mayor walk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1C8</th>\n",
       "      <td>original release date november   wednesday and...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             transcript\n",
       "T1C1  original release date november   wednesday add...\n",
       "T1C2  original release date november   wednesday con...\n",
       "T1C3  original release date november   wednesday fin...\n",
       "T1C4  original release date november   wednesday and...\n",
       "T1C5  original release date november    years ago go...\n",
       "T1C6  original release date november   wednesday att...\n",
       "T1C7  original release date november   at mayor walk...\n",
       "T1C8  original release date november   wednesday and..."
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lea los datos limpios, antes del paso CountVectorizer\n",
    "data_clean = pd.read_pickle('data_clean.pkl')\n",
    "data_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>T1C1</th>\n",
       "      <td>release date november student brother pugsley ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1C2</th>\n",
       "      <td>release date november sheriff galpin perpetrat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1C3</th>\n",
       "      <td>release date november members students society...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1C4</th>\n",
       "      <td>release date november wednesday thing break co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1C5</th>\n",
       "      <td>release date years gomez suspicion garrett gat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1C6</th>\n",
       "      <td>release date november wednesday attempts goody...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1C7</th>\n",
       "      <td>release date november mayor walkers notices fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1C8</th>\n",
       "      <td>release date november wednesday classmates tyl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             transcript\n",
       "T1C1  release date november student brother pugsley ...\n",
       "T1C2  release date november sheriff galpin perpetrat...\n",
       "T1C3  release date november members students society...\n",
       "T1C4  release date november wednesday thing break co...\n",
       "T1C5  release date years gomez suspicion garrett gat...\n",
       "T1C6  release date november wednesday attempts goody...\n",
       "T1C7  release date november mayor walkers notices fi...\n",
       "T1C8  release date november wednesday classmates tyl..."
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aplique la función de sustantivos a las transcripciones para filtrar solo por sustantivos\n",
    "data_nouns = pd.DataFrame(data_clean.transcript.apply(nouns))\n",
    "data_nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ProgramFiles\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abilities</th>\n",
       "      <th>ability</th>\n",
       "      <th>abomination</th>\n",
       "      <th>abominations</th>\n",
       "      <th>academy</th>\n",
       "      <th>accident</th>\n",
       "      <th>accounts</th>\n",
       "      <th>accusations</th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>...</th>\n",
       "      <th>yonder</th>\n",
       "      <th>youd</th>\n",
       "      <th>youll</th>\n",
       "      <th>youve</th>\n",
       "      <th>yuck</th>\n",
       "      <th>zero</th>\n",
       "      <th>zombies</th>\n",
       "      <th>zone</th>\n",
       "      <th>zurich</th>\n",
       "      <th>ça</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>T1C1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1C2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1C3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1C4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1C5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1C6</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1C7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1C8</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 2438 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      abilities  ability  abomination  abominations  academy  accident  \\\n",
       "T1C1          0        0            0             0        1         1   \n",
       "T1C2          0        1            0             0        0         2   \n",
       "T1C3          1        1            0             1        1         0   \n",
       "T1C4          0        1            0             0        0         1   \n",
       "T1C5          1        1            0             0        0         2   \n",
       "T1C6          0        2            0             0        0         0   \n",
       "T1C7          0        0            0             0        0         0   \n",
       "T1C8          0        1            1             1        0         0   \n",
       "\n",
       "      accounts  accusations  act  action  ...  yonder  youd  youll  youve  \\\n",
       "T1C1         0            0    0       0  ...       0     0      4      4   \n",
       "T1C2         0            0    1       0  ...       0     0      0      2   \n",
       "T1C3         0            0    0       0  ...       1     0      1      1   \n",
       "T1C4         0            0    1       0  ...       0     1      0      0   \n",
       "T1C5         1            0    0       0  ...       0     0      0      2   \n",
       "T1C6         0            0    2       1  ...       0     0      2      1   \n",
       "T1C7         0            0    0       0  ...       0     0      2      3   \n",
       "T1C8         0            1    1       1  ...       0     0      0      2   \n",
       "\n",
       "      yuck  zero  zombies  zone  zurich  ça  \n",
       "T1C1     0     1        0     0       0   1  \n",
       "T1C2     0     0        0     0       0   0  \n",
       "T1C3     1     0        1     0       0   0  \n",
       "T1C4     0     1        0     1       0   0  \n",
       "T1C5     0     0        0     0       0   0  \n",
       "T1C6     0     0        0     0       0   0  \n",
       "T1C7     0     0        0     0       1   0  \n",
       "T1C8     0     1        0     0       0   0  \n",
       "\n",
       "[8 rows x 2438 columns]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Crea una nueva matriz documento-término usando solo sustantivos\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Vuelva a agregar las palabras vacías adicionales ya que estamos recreando la matriz documento-término\n",
    "add_stop_words = ['like', 'im', 'know', 'just', 'dont', 'thats', 'right', 'people',\n",
    "                  'youre', 'got', 'gonna', 'time', 'think', 'yeah', 'said']\n",
    "stop_words = text.ENGLISH_STOP_WORDS.union(add_stop_words)\n",
    "\n",
    "# Recrear una matriz documento-término con solo sustantivos\n",
    "cvn = CountVectorizer(stop_words=stop_words)\n",
    "data_cvn = cvn.fit_transform(data_nouns.transcript)\n",
    "data_dtmn = pd.DataFrame(data_cvn.toarray(), columns=cvn.get_feature_names())\n",
    "data_dtmn.index = data_nouns.index\n",
    "data_dtmn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Crear el corpus gensim\n",
    "corpusn = matutils.Sparse2Corpus(scipy.sparse.csr_matrix(data_dtmn.transpose()))\n",
    "\n",
    "# Crear el diccionario de vocabulario\n",
    "id2wordn = dict((v, k) for k, v in cvn.vocabulary_.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.010*\"tyler\" + 0.010*\"gates\" + 0.009*\"wednesday\" + 0.009*\"thing\" + 0.008*\"father\" + 0.008*\"hyde\" + 0.007*\"monster\" + 0.007*\"mother\" + 0.007*\"school\" + 0.007*\"family\"'),\n",
       " (1,\n",
       "  '0.009*\"monster\" + 0.008*\"dance\" + 0.008*\"wednesday\" + 0.008*\"thing\" + 0.007*\"hes\" + 0.007*\"crackstone\" + 0.006*\"date\" + 0.006*\"kind\" + 0.005*\"goo\" + 0.005*\"night\"'),\n",
       " (2,\n",
       "  '0.011*\"wednesday\" + 0.010*\"thing\" + 0.009*\"school\" + 0.007*\"rowan\" + 0.007*\"mother\" + 0.007*\"way\" + 0.005*\"monster\" + 0.005*\"cup\" + 0.004*\"scales\" + 0.004*\"years\"'),\n",
       " (3,\n",
       "  '0.001*\"wednesday\" + 0.001*\"thing\" + 0.001*\"school\" + 0.001*\"way\" + 0.001*\"monster\" + 0.001*\"hes\" + 0.001*\"mother\" + 0.001*\"dad\" + 0.001*\"family\" + 0.001*\"friends\"')]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Probemos 4 temas\n",
    "ldan = models.LdaModel(corpus=corpusn, num_topics=4, id2word=id2wordn, passes=10)\n",
    "ldan.print_topics()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identificar topicos de solo sustantivos y adjetivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Vamos a crear una función para extraer sustantivos de una cadena de texto\n",
    "def nouns_adj(text):\n",
    "    '''Dada una cadena de texto, tokenice el texto y extraiga solo los sustantivos y adjetivos.'''\n",
    "    is_noun_adj = lambda pos: pos[:2] == 'NN' or pos[:2] == 'JJ'\n",
    "    tokenized = word_tokenize(text)\n",
    "    nouns_adj = [word for (word, pos) in pos_tag(tokenized) if is_noun_adj(pos)] \n",
    "    return ' '.join(nouns_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>T1C1</th>\n",
       "      <td>original release date november wednesday highs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1C2</th>\n",
       "      <td>original release date november wednesday skept...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1C3</th>\n",
       "      <td>original release date november wednesday membe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1C4</th>\n",
       "      <td>original release date november wednesday thing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1C5</th>\n",
       "      <td>original release date years gomez suspicion ga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1C6</th>\n",
       "      <td>original release date november wednesday attem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1C7</th>\n",
       "      <td>original release date november mayor walkers f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1C8</th>\n",
       "      <td>original release date november wednesday class...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             transcript\n",
       "T1C1  original release date november wednesday highs...\n",
       "T1C2  original release date november wednesday skept...\n",
       "T1C3  original release date november wednesday membe...\n",
       "T1C4  original release date november wednesday thing...\n",
       "T1C5  original release date years gomez suspicion ga...\n",
       "T1C6  original release date november wednesday attem...\n",
       "T1C7  original release date november mayor walkers f...\n",
       "T1C8  original release date november wednesday class..."
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aplique la función de sustantivos a las transcripciones para filtrar solo por sustantivos\n",
    "data_nouns_adj = pd.DataFrame(data_clean.transcript.apply(nouns_adj))\n",
    "data_nouns_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ProgramFiles\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abilities</th>\n",
       "      <th>ability</th>\n",
       "      <th>able</th>\n",
       "      <th>abominable</th>\n",
       "      <th>abomination</th>\n",
       "      <th>abominations</th>\n",
       "      <th>academy</th>\n",
       "      <th>accept</th>\n",
       "      <th>accident</th>\n",
       "      <th>accounts</th>\n",
       "      <th>...</th>\n",
       "      <th>youd</th>\n",
       "      <th>youll</th>\n",
       "      <th>young</th>\n",
       "      <th>youthful</th>\n",
       "      <th>yuck</th>\n",
       "      <th>zero</th>\n",
       "      <th>zombies</th>\n",
       "      <th>zone</th>\n",
       "      <th>zurich</th>\n",
       "      <th>ça</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>T1C1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1C2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1C3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1C4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1C5</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1C6</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1C7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T1C8</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 3006 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      abilities  ability  able  abominable  abomination  abominations  \\\n",
       "T1C1          0        0     0           0            0             0   \n",
       "T1C2          0        1     1           0            0             0   \n",
       "T1C3          1        1     2           0            0             1   \n",
       "T1C4          0        1     1           1            0             0   \n",
       "T1C5          1        1     0           0            0             0   \n",
       "T1C6          0        2     1           0            0             0   \n",
       "T1C7          0        0     1           0            0             0   \n",
       "T1C8          0        1     1           0            1             1   \n",
       "\n",
       "      academy  accept  accident  accounts  ...  youd  youll  young  youthful  \\\n",
       "T1C1        1       1         1         0  ...     0      5      0         0   \n",
       "T1C2        0       0         2         0  ...     1      0      0         0   \n",
       "T1C3        2       0         0         0  ...     0      1      1         0   \n",
       "T1C4        0       0         1         0  ...     1      0      0         0   \n",
       "T1C5        0       0         2         1  ...     1      0      0         1   \n",
       "T1C6        0       0         0         0  ...     0      2      0         0   \n",
       "T1C7        0       0         0         0  ...     0      3      1         0   \n",
       "T1C8        0       0         0         0  ...     1      0      1         0   \n",
       "\n",
       "      yuck  zero  zombies  zone  zurich  ça  \n",
       "T1C1     0     1        0     0       0   1  \n",
       "T1C2     0     0        0     0       0   0  \n",
       "T1C3     2     0        1     0       0   0  \n",
       "T1C4     0     1        0     1       0   0  \n",
       "T1C5     0     0        0     0       0   0  \n",
       "T1C6     0     0        0     0       0   0  \n",
       "T1C7     0     0        0     0       1   0  \n",
       "T1C8     0     1        0     0       0   0  \n",
       "\n",
       "[8 rows x 3006 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cree una nueva matriz de término de documento usando solo sustantivos y adjetivos, también elimine palabras comunes con max_df\n",
    "cvna = CountVectorizer(stop_words=stop_words, max_df=.8)\n",
    "data_cvna = cvna.fit_transform(data_nouns_adj.transcript)\n",
    "data_dtmna = pd.DataFrame(data_cvna.toarray(), columns=cvna.get_feature_names())\n",
    "data_dtmna.index = data_nouns_adj.index\n",
    "data_dtmna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Crear el corpus gensim\n",
    "corpusna = matutils.Sparse2Corpus(scipy.sparse.csr_matrix(data_dtmna.transpose()))\n",
    "\n",
    "# Crear el diccionario de vocabulario\n",
    "id2wordna = dict((v, k) for k, v in cvna.vocabulary_.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.010*\"crackstone\" + 0.006*\"house\" + 0.006*\"meeting\" + 0.005*\"pilgrim\" + 0.005*\"joseph\" + 0.004*\"jericho\" + 0.004*\"visions\" + 0.004*\"history\" + 0.004*\"witch\" + 0.003*\"book\"'),\n",
       " (1,\n",
       "  '0.014*\"garrett\" + 0.007*\"gates\" + 0.004*\"gomez\" + 0.004*\"best\" + 0.004*\"murder\" + 0.003*\"eugene\" + 0.003*\"dance\" + 0.003*\"morticia\" + 0.003*\"nightshade\" + 0.003*\"mom\"'),\n",
       " (2,\n",
       "  '0.005*\"cup\" + 0.004*\"scales\" + 0.004*\"bianca\" + 0.004*\"poe\" + 0.003*\"look\" + 0.003*\"murder\" + 0.003*\"wait\" + 0.003*\"dark\" + 0.003*\"roommate\" + 0.003*\"girls\"'),\n",
       " (3,\n",
       "  '0.010*\"hyde\" + 0.008*\"gates\" + 0.007*\"eugene\" + 0.007*\"dance\" + 0.006*\"raven\" + 0.005*\"goody\" + 0.005*\"mayor\" + 0.004*\"kinbott\" + 0.004*\"laurel\" + 0.004*\"god\"')]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Probemos 4 temas\n",
    "ldana = models.LdaModel(corpus=corpusna, num_topics=4, id2word=id2wordna, passes=10)\n",
    "ldana.print_topics()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identificar topicos en todo el documento"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De los 9 modelos de temas que vimos, los sustantivos y adjetivos, 4 temas uno tenía más sentido. Así que saquemos eso aquí abajo y analicemos algunas iteraciones más para obtener temas más afinados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.007*\"hyde\" + 0.006*\"gates\" + 0.005*\"mayor\" + 0.004*\"goody\" + 0.004*\"kinbott\" + 0.004*\"cup\" + 0.004*\"diary\" + 0.003*\"poe\" + 0.003*\"scales\" + 0.003*\"laurel\"'),\n",
       " (1,\n",
       "  '0.009*\"garrett\" + 0.004*\"murder\" + 0.004*\"gates\" + 0.003*\"gomez\" + 0.003*\"best\" + 0.003*\"session\" + 0.003*\"week\" + 0.003*\"morticia\" + 0.002*\"therapy\" + 0.002*\"home\"'),\n",
       " (2,\n",
       "  '0.010*\"crackstone\" + 0.006*\"house\" + 0.006*\"meeting\" + 0.006*\"pilgrim\" + 0.006*\"joseph\" + 0.004*\"jericho\" + 0.004*\"visions\" + 0.004*\"witch\" + 0.004*\"history\" + 0.003*\"book\"'),\n",
       " (3,\n",
       "  '0.010*\"eugene\" + 0.009*\"dance\" + 0.007*\"raven\" + 0.006*\"hyde\" + 0.005*\"goo\" + 0.005*\"god\" + 0.004*\"sorry\" + 0.004*\"crackstone\" + 0.004*\"gates\" + 0.004*\"blood\"')]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Nuestro modelo LDA final (por ahora)\n",
    "ldana = models.LdaModel(corpus=corpusna, num_topics=4, id2word=id2wordna, passes=80)\n",
    "ldana.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These four topics look pretty decent. Let's settle on these for now.\n",
    "* Topic 0: mom, parents\n",
    "* Topic 1: husband, wife\n",
    "* Topic 2: guns\n",
    "* Topic 3: profanity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 'T1C1'),\n",
       " (0, 'T1C2'),\n",
       " (2, 'T1C3'),\n",
       " (3, 'T1C4'),\n",
       " (1, 'T1C5'),\n",
       " (0, 'T1C6'),\n",
       " (0, 'T1C7'),\n",
       " (3, 'T1C8')]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Echemos un vistazo a los temas que contiene cada transcripción\n",
    "corpus_transformed = ldana[corpusna]\n",
    "list(zip([a for [(a,b)] in corpus_transformed], data_dtmna.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "For a first pass of LDA, these kind of make sense to me, so we'll call it a day for now.\n",
    "* Topic 0: mom, parents [Anthony, Hasan, Louis, Ricky]\n",
    "* Topic 1: husband, wife [Ali, John, Mike]\n",
    "* Topic 2: guns [Bill, Bo, Jim]\n",
    "* Topic 3: profanity [Dave, Joe]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ¡FIN TRABAJO!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
